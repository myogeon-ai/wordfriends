# pip install streamlit
# pip install SpeechRecognition
# pip install gtts
# pip install googletrans
# pip install difflib   # ì„¤ì¹˜ ì•ˆí•´ë„ ì‚¬ìš©ê°€ëŠ¥
# pip install sounddevice
# pip install audio-recorder-streamlit
import streamlit as st
import speech_recognition as sr
from gtts import gTTS
import os
import random
import time
import difflib
from googletrans import Translator
import sounddevice as sd
import numpy as np
# from scipy import signal
from audio_recorder_streamlit import audio_recorder  


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'current_word' not in st.session_state:
        st.session_state.current_word = ''
    if 'score' not in st.session_state:
        st.session_state.score = 0
    if 'total_attempts' not in st.session_state:
        st.session_state.total_attempts = 0
    if 'selected_gender' not in st.session_state:
        st.session_state.selected_gender = 'Boy'

def get_random_word():
    """ë¬´ì‘ìœ„ ë‹¨ì–´ ì„ íƒ"""
    words = [
        "apple", "banana", "orange", "grape", "strawberry",
        "computer", "python", "programming", "artificial", "intelligence",
        "beautiful", "wonderful", "amazing", "fantastic", "excellent"
    ]
    return random.choice(words)

def create_audio(text, gender):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (ì„±ë³„ì— ë”°ë¥¸ ì„¤ì • ì ìš©)"""
    # ì„±ë³„ì— ë”°ë¥¸ ì–¸ì–´ ì„¤ì •
    if gender == 'Boy':
        tts = gTTS(text=text, lang='en', tld='co.uk')  # ì˜êµ­ ì˜ì–´ (ë‚¨ì„±ìŠ¤ëŸ¬ìš´ ìŒìƒ‰)
    else:
        tts = gTTS(text=text, lang='en', tld='com')    # ë¯¸êµ­ ì˜ì–´ (ì—¬ì„±ìŠ¤ëŸ¬ìš´ ìŒìƒ‰)
    
    filename = "word.mp3"
    tts.save(filename)
    return filename

# def speech_to_text():
#     """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
#     r = sr.Recognizer()
#     with sr.Microphone() as source:
#         st.write("ë§ì”€í•´ì£¼ì„¸ìš”...")
#         try:
#             audio = r.listen(source, timeout=5, phrase_time_limit=5)
#             text = r.recognize_google(audio, language='en-US')
#             return text.lower()
#         except sr.WaitTimeoutError:
#             st.error("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
#             return None
#         except sr.UnknownValueError:
#             st.error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
#             return None
#         except sr.RequestError:
#             st.error("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#             return None
 
    
# def speech_to_text():  
#     """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""  
#     r = sr.Recognizer()  
    
#     # ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  placeholder ìƒì„±  
#     status_placeholder = st.empty()  
    
#     # ì˜¤ë””ì˜¤ ë…¹ìŒ ì»´í¬ë„ŒíŠ¸  
#     status_placeholder.write("ğŸ¤ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§ì”€í•´ì£¼ì„¸ìš”...")  
#     # audio_bytes = audio_recorder(  
#     #     text="",  # ë²„íŠ¼ í…ìŠ¤íŠ¸  
#     #     recording_color="#e8b62c",  # ë…¹ìŒ ì¤‘ ìƒ‰ìƒ  
#     #     neutral_color="#6aa36f",    # ê¸°ë³¸ ìƒ‰ìƒ  
#     #     stopping_color="#941100"     # ì •ì§€ ìƒ‰ìƒ  
#     # )  
#     audio_bytes = audio_recorder()  # íŒŒë¼ë¯¸í„° ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì‚¬ìš© 
    
#     # ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ìˆì„ ê²½ìš° ì²˜ë¦¬  
#     if audio_bytes:  
#         try:  
#             # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥í•˜ê²Œ í‘œì‹œ  
#             st.audio(audio_bytes, format="audio/wav")  
            
#             status_placeholder.info("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")  
            
#             # ìŒì„± ì¸ì‹  
#             audio_data = sr.AudioData(audio_bytes,   
#                                     sample_rate=44100,  # ìƒ˜í”Œë§ ë ˆì´íŠ¸  
#                                     sample_width=2)     # ìƒ˜í”Œ ë„ˆë¹„  
            
#             # ì˜ì–´ ìŒì„± ì¸ì‹ (í•œêµ­ì–´ì˜ ê²½ìš° 'ko-KR'ë¡œ ë³€ê²½)  
#             text = r.recognize_google(audio_data, language='en-US')  
            
#             # ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ëœ ê²½ìš°  
#             status_placeholder.success("ìŒì„± ì¸ì‹ ì™„ë£Œ!")
#             print(text.lower() )
#             return text.lower()  
            
#         except sr.WaitTimeoutError:  
#             status_placeholder.error("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")  
#             return None  
#         except sr.UnknownValueError:  
#             status_placeholder.error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")  
#             return None  
#         except sr.RequestError:  
#             status_placeholder.error("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")  
#             return None  
#         except Exception as e:  
#             status_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")  
#             return None  
    
#     return None      
        
# def speech_to_text():

#     """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""  
#     r = sr.Recognizer()  
    
#     # ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  placeholder ìƒì„±  
#     status_placeholder = st.empty()  

    
#     # # ë§ˆì´í¬ ê¶Œí•œ ì•ˆë‚´ ë©”ì‹œì§€  
#     # st.info("ğŸ§ ë§ˆì´í¬ ì‚¬ìš©ì„ í—ˆìš©í•´ì£¼ì„¸ìš”. ì²˜ìŒ ì‹¤í–‰ì‹œ ë¸Œë¼ìš°ì €ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤.")  
    
#     # ì˜¤ë””ì˜¤ ë…¹ìŒ ì»´í¬ë„ŒíŠ¸  
#     status_placeholder.write("ğŸ§ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§ì”€í•´ì£¼ì„¸ìš”...")  

    
#     # # audio_recorder ì»´í¬ë„ŒíŠ¸ ì¶”ê°€  
#     audio_bytes = audio_recorder(  
#         pause_threshold=2.0,  # 2ì´ˆ ë™ì•ˆ ì†Œë¦¬ê°€ ì—†ìœ¼ë©´ ìë™ ì •ì§€  
#         sample_rate=44100  
#     )  
#     # # audio_recorder ì»´í¬ë„ŒíŠ¸ ì¶”ê°€  
#     # audio_bytes = audio_recorder()

    
#     # ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ìˆì„ ê²½ìš° ì²˜ë¦¬  
#     if audio_bytes:
    
#         try:  
#             # ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ë¸Œë¼ìš°ì € ì²˜ë¦¬ ì‹œê°„ ì œê³µ  
#             time.sleep(0.5)

            
#             # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥í•˜ê²Œ í‘œì‹œ  
#             st.audio(audio_bytes, format="audio/wav")  
            
#             status_placeholder.info("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")  
            
#             # ìŒì„± ì¸ì‹  
#             audio_data = sr.AudioData(audio_bytes,   
#                                     sample_rate=44100,  
#                                     sample_width=2)  
            
#             # ì˜ì–´ ìŒì„± ì¸ì‹ (í•œêµ­ì–´ì˜ ê²½ìš° 'ko-KR'ë¡œ ë³€ê²½)  
#             text = r.recognize_google(audio_data, language='en-US')  

#             # ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ëœ ê²½ìš°  
#             status_placeholder.success("ìŒì„± ì¸ì‹ ì™„ë£Œ!")  
#             return text.lower()  
            
#         except sr.WaitTimeoutError:  
#             status_placeholder.error("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")  
#             return None  
#         except sr.UnknownValueError:  
#             status_placeholder.error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")  
#             return None  
#         except sr.RequestError:  
#             status_placeholder.error("ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")  
#             return None  
#         except Exception as e:  
#             status_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")  
#             return None  
#         except Exception as e:  
#             st.error(f"ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}")  
#             st.info("ë¸Œë¼ìš°ì €ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")  
#             return None  

#     return None      
 
# # =================================================================================================
# # =================================================================================================
# # Streamlit Cloudì—ì„œ ë…¹ìŒ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ” ì£¼ìš” ì›ì¸ê³¼ í•´ê²° ë°©ë²•ì„ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

# # ì£¼ìš” ë¬¸ì œì :
# # Streamlit CloudëŠ” ì„œë²„ í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì§ì ‘ì ì¸ ë§ˆì´í¬ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
# # sounddeviceì™€ ê°™ì€ ë¡œì»¬ ì˜¤ë””ì˜¤ ì¥ì¹˜ì— ì˜ì¡´í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” Cloud í™˜ê²½ì—ì„œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# # audio_recorder_streamlitì€ ë¸Œë¼ìš°ì € ê¸°ë°˜ ë…¹ìŒì„ ì§€ì›í•˜ì§€ë§Œ, ì„œë²„ í™˜ê²½ì—ì„œ í•„ìš”í•œ ì˜ì¡´ì„± ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# # í•´ê²° ë°©ì•ˆ:
# # ì•„ë˜ì™€ ê°™ì´ ì½”ë“œë¥¼ ìˆ˜ì •í•´ë³´ì„¸ìš”:
# # python

# # import streamlit as st  
# # import speech_recognition as sr  
# # from gtts import gTTS  
# # import os  
# # import random  
# # import time  
# # import difflib  
# # from googletrans import Translator  
# from io import BytesIO  
# import wave  

# # streamlit-webrtc ì‚¬ìš©  
# from streamlit_webrtc import webrtc_streamer, WebRtcMode, ClientSettings  

# def speech_to_text():  
#     """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""  
#     r = sr.Recognizer()  
#     status_placeholder = st.empty()  
    
#     # webrtc_streamerë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ìº¡ì²˜  
#     webrtc_ctx = webrtc_streamer(  
#         key="speech-to-text",  
#         mode=WebRtcMode.AUDIO_RECORDER,  
#         client_settings=ClientSettings(  
#             rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},  
#             media_stream_constraints={"audio": True},  
#         ),  
#     )  

#     if webrtc_ctx.audio_receiver:  
#         if webrtc_ctx.state.playing:  
#             status_placeholder.write("ğŸ¤ ë…¹ìŒ ì¤‘...")  
#         elif webrtc_ctx.audio_receiver.audio_data is not None:  
#             # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬  
#             try:  
#                 audio_data = webrtc_ctx.audio_receiver.audio_data  
                
#                 # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜  
#                 wav_bytes = BytesIO()  
#                 with wave.open(wav_bytes, 'wb') as wav_file:  
#                     wav_file.setnchannels(1)  
#                     wav_file.setsampwidth(2)  
#                     wav_file.setframerate(16000)  
#                     wav_file.writeframes(audio_data.tobytes())  
                
#                 # ìŒì„± ì¸ì‹  
#                 audio = sr.AudioData(wav_bytes.getvalue(),   
#                                    sample_rate=16000,  
#                                    sample_width=2)  
#                 text = r.recognize_google(audio, language='en-US')  
                
#                 status_placeholder.success("ìŒì„± ì¸ì‹ ì™„ë£Œ!")  
#                 return text.lower()  
                
#             except Exception as e:  
#                 status_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")  
#                 return None  
    
#     return None  

# # requirements.txtì— ì¶”ê°€í•´ì•¼ í•  íŒ¨í‚¤ì§€:  
# # streamlit-webrtc  
# # aioice  
# # aiortc  
# # av

# # ì£¼ìš” ë³€ê²½ì‚¬í•­:
# # audio_recorder_streamlit ëŒ€ì‹  streamlit-webrtc ì‚¬ìš©
# # WebRTCë¥¼ í†µí•œ ë¸Œë¼ìš°ì € ê¸°ë°˜ ì˜¤ë””ì˜¤ ìº¡ì²˜ êµ¬í˜„
# # ì„œë²„ í™˜ê²½ì—ì„œë„ ì‘ë™ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ë³€ê²½
# # ì„¤ì¹˜ í•„ìš” íŒ¨í‚¤ì§€:
# # streamlit-webrtc  
# # aioice  
# # aiortc  
# # av  
# # ì¶”ê°€ ì„¤ì •:
# # requirements.txt íŒŒì¼ì— ìœ„ì˜ íŒ¨í‚¤ì§€ë“¤ì„ ì¶”ê°€
# # Streamlit Cloudì˜ ì„¤ì •ì—ì„œ Python 3.7 ì´ìƒ ë²„ì „ ì‚¬ìš© í™•ì¸
# # ì£¼ì˜ì‚¬í•­:
# # HTTPS í™˜ê²½ì—ì„œë§Œ ë§ˆì´í¬ ì ‘ê·¼ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ (Streamlit CloudëŠ” ê¸°ë³¸ì ìœ¼ë¡œ HTTPS ì œê³µ)
# # ë¸Œë¼ìš°ì €ì˜ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ì´ í•„ìš”í•©ë‹ˆë‹¤
# # ì²« ì‹¤í–‰ ì‹œ ì•½ê°„ì˜ ì§€ì—°ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
# # ì´ëŸ¬í•œ ë³€ê²½ì‚¬í•­ì„ ì ìš©í•˜ë©´ Streamlit Cloud í™˜ê²½ì—ì„œë„ ë…¹ìŒ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ WebRTCë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ë” ì•ˆì •ì ì¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.
# # =================================================================================================
# # =================================================================================================


# # =================================================================================================
# # =================================================================================================

# def speech_to_text():  
#     """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""  
#     r = sr.Recognizer()  
#     status_placeholder = st.empty()  
    
#     # ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜  
#     def audio_frames_callback(frames):  
#         sound = np.frombuffer(frames, dtype=np.int16)  
#         return sound  
    
#     # webrtc_streamer ì„¤ì •  
#     webrtc_ctx = webrtc_streamer(  
#         key="speech-to-text",  
#         rtc_configuration=RTCConfiguration(  
#             {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}  
#         ),  
#         media_stream_constraints={  
#             "video": False,  
#             "audio": True,  
#         },  
#         audio_receiver_size=1024,  
#         async_processing=True,  
#     )  

#     if webrtc_ctx.audio_receiver:  
#         if webrtc_ctx.state.playing:  
#             status_placeholder.write("ğŸ¤ ë…¹ìŒ ì¤‘...")  
#             try:  
#                 # ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘  
#                 audio_frames = webrtc_ctx.audio_receiver.get_frames()  
#                 if audio_frames:  
#                     # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜  
#                     audio_data = b''.join([frame.to_ndarray().tobytes() for frame in audio_frames])  
                    
#                     # WAV íŒŒì¼ ìƒì„±  
#                     wav_bytes = BytesIO()  
#                     with wave.open(wav_bytes, 'wb') as wav_file:  
#                         wav_file.setnchannels(1)  
#                         wav_file.setsampwidth(2)  
#                         wav_file.setframerate(16000)  
#                         wav_file.writeframes(audio_data)  
                    
#                     # ìŒì„± ì¸ì‹  
#                     audio = sr.AudioData(wav_bytes.getvalue(),   
#                                        sample_rate=16000,  
#                                        sample_width=2)  
#                     text = r.recognize_google(audio, language='en-US')  
                    
#                     status_placeholder.success("ìŒì„± ì¸ì‹ ì™„ë£Œ!")  
#                     return text.lower()  
                    
#             except Exception as e:  
#                 status_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")  
#                 return None  
    
#     return None  


# # =================================================================================================
# # =================================================================================================
# 
import streamlit as st  
from streamlit_mic_recorder import mic_recorder  
import speech_recognition as sr  
from io import BytesIO  

def speech_to_text():  
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""  
    r = sr.Recognizer()  
    status_placeholder = st.empty()  
    
    # ë§ˆì´í¬ ë…¹ìŒ  
    audio = mic_recorder(  
        key="recorder",  
        start_prompt="ë…¹ìŒ ì‹œì‘",  
        stop_prompt="ë…¹ìŒ ì¤‘ì§€",  
        just_once=True  
    )  
    
    if audio:  
        try:  
            # ìŒì„± ì¸ì‹  
            audio_data = sr.AudioData(audio,   
                                    sample_rate=44100,  
                                    sample_width=2)  
            text = r.recognize_google(audio_data, language='en-US')  
            
            status_placeholder.success("ìŒì„± ì¸ì‹ ì™„ë£Œ!")  
            return text.lower()  
            
        except Exception as e:  
            status_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")  
            return None  
    
    return None
# # =================================================================================================
# # =================================================================================================
# 

def calculate_similarity(word1, word2):
    """ë‘ ë‹¨ì–´ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    return difflib.SequenceMatcher(None, word1, word2).ratio()

def get_character_emoji(gender):
    """ì„±ë³„ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    return "ğŸ‘¦" if gender == 'Boy' else "ğŸ‘§"

def main():
    # st.title("Word Friends")
    # st.title("AI ì¹œêµ¬ì™€ ë‹¨ì–´ë¥¼ í•™ìŠµí•´ë³´ì„¸ìš”")
    # st.title("ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”")

    st.write("""  
        <div style='text-align: center;'>  
            <h1>Word Friends</h1>
            <h5>AI ì¹œêµ¬ì™€ ë‹¨ì–´ë¥¼ í•™ìŠµí•´ë³´ì„¸ìš”</h5>
            </br>
            </br>
            </br>
            <h4>ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”</h4>
        </div>  
        """, unsafe_allow_html=True)
    
            
        
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
        
    # # ì²« ì‹¤í–‰ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ  
    # if st.session_state.is_first_run:  
    #     st.info("ğŸ‘‹ ì²˜ìŒ ì‚¬ìš©í•˜ì‹œë‚˜ìš”? ë¸Œë¼ìš°ì €ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”!")  
    #     st.session_state.is_first_run = False  
    # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€  
    # st.markdown("""  
    # ### ì‚¬ìš© ë°©ë²•  
    # 1. ë¸Œë¼ìš°ì €ì˜ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”  
    # 2. ì•„ë˜ ë…¹ìŒ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§ì”€í•´ì£¼ì„¸ìš”  
    # 3. ë‹¤ì‹œ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë…¹ìŒì´ ì¢…ë£Œë©ë‹ˆë‹¤  
    # """)  
        
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •  
    topic_image_paths = {  
        'School': './image/School.png',   # ì£¼ì œ í•™êµ ì´ë¯¸ì§€ ê²½ë¡œ
        'Family': './image/Family.png',   # ì£¼ì œ ê°€ì¡± ì´ë¯¸ì§€ ê²½ë¡œ
        'Animals': './image/Animals.png',   # ì£¼ì œ ë™ë¬¼ ì´ë¯¸ì§€ ê²½ë¡œ
        'Weather': './image/Weather.png',   # ì£¼ì œ ë‚ ì”¨ ì´ë¯¸ì§€ ê²½ë¡œ
        'Food': './image/Food.png'   # ì£¼ì œ ìŒì‹ ì´ë¯¸ì§€ ê²½ë¡œ
    }  

    
    
    # ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”  
    if 'selected_image' not in st.session_state:  
        st.session_state.selected_image = None  

    # ì´ë¯¸ì§€ í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬  
    def select_image(image_key):  
        st.session_state.selected_image = image_key  

    col1, col2, col3, col4, col5 = st.columns(5)  

    with col1:  
        if st.button("School"):  
            select_image('School')  
        st.image(topic_image_paths['School'], caption='School', use_column_width=True)  

    with col2:  
        if st.button("Family"):  
            select_image('Family')  
        st.image(topic_image_paths['Family'], caption='Family', use_column_width=True)
        
    with col3:  
        if st.button("Animals"):  
            select_image('Animals')  
        st.image(topic_image_paths['Animals'], caption='Animals', use_column_width=True)  

    with col4:  
        if st.button("Weather"):  
            select_image('Weather')  
        st.image(topic_image_paths['Weather'], caption='Weather', use_column_width=True)
        
    with col5:  
        if st.button("Food"):  
            select_image('Food')  
        st.image(topic_image_paths['Food'], caption='Food', use_column_width=True)  

    # ì„ íƒëœ ì´ë¯¸ì§€ í‘œì‹œ  
    if st.session_state.selected_image:  
        st.write(f"Hello {st.session_state.selected_image}")
        



    # ìºë¦­í„° ì„ íƒ
    st.write("""  
    <div style='text-align: center;'>  
        <h4>AI ì¹œêµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”</h4>
    </div>  
    """, unsafe_allow_html=True)

    # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •  
    image_paths = {  
        'Boy': './image/boy.png',   # ë‚¨ìì•„ì´ ì´ë¯¸ì§€ ê²½ë¡œ  
        'Girl': './image/girl.png'   # ì—¬ìì•„ì´ ì´ë¯¸ì§€ ê²½ë¡œ  
    }  

    
    
    # ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”  
    if 'selected_image' not in st.session_state:  
        st.session_state.selected_image = None  

    # ì´ë¯¸ì§€ í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬  
    def select_image(image_key):  
        st.session_state.selected_image = image_key  

    col1, col2 = st.columns(2)  

    with col1:  
        if st.button("Boy"):  
            select_image('Boy')  
        st.image(image_paths['Boy'], caption='Boy', use_column_width=True)  

    with col2:  
        if st.button("Girl"):  
            select_image('Girl')  
        st.image(image_paths['Girl'], caption='Girl', use_column_width=True)  

    # ì„ íƒëœ ì´ë¯¸ì§€ í‘œì‹œ  
    if st.session_state.selected_image:  
        st.write(f"Hello {st.session_state.selected_image}")

        
                
        
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown("---")
    
    
    st.write("""  
    <div style='text-align: center;'>  
        <h6>ë“£ê³  ë”°ë¼ ì½ê¸°</h6>
        <h2 style='text-align: center; color: rgb(205, 118, 242);'>Listen and Repeat</h2>
        </br>
        <h6>Play ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¨ì–´ë¥¼ ë“£ê³ </h6>
        <h6>Mic ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”</h6>
    </div>  
    """, unsafe_allow_html=True)





    # ì‚¬ì´ë“œë°”ì— ì ìˆ˜ í‘œì‹œ
    st.sidebar.header("ì ìˆ˜")
    st.sidebar.write(f"ì •í™•ë„: {st.session_state.score}/{st.session_state.total_attempts if st.session_state.total_attempts > 0 else 1:.2%}")
    
    test = [1, 2, 3, 4, 5]
    for i in test:
        col1, col2 = st.columns([1, 1])
        # ìƒˆ ë‹¨ì–´ ë°›ê¸° ë²„íŠ¼
        with col1: 
            st.image(image_paths['Boy'], width=200, caption='Boy')
        with col2: 
            if st.button("PLAY", key="play_button_" + str(i)):
                st.session_state.current_word = get_random_word()
                audio_file = create_audio(st.session_state.current_word, st.session_state.selected_gender)
                
                # ë‹¨ì–´ì™€ ë°œìŒ ë“£ê¸° ë²„íŠ¼ í‘œì‹œ
                st.write(f"## ì´ ë‹¨ì–´ë¥¼ ì½ì–´ë³´ì„¸ìš”: **{st.session_state.current_word}**")
                st.audio(audio_file)
                
                # í•œêµ­ì–´ ì˜ë¯¸ í‘œì‹œ
                translator = Translator()
                try:
                    korean_meaning = translator.translate(st.session_state.current_word, dest='ko').text
                    st.write(f"ë‹¨ì–´ ëœ»: {korean_meaning}")
                except:
                    st.write("ë‹¨ì–´ ëœ»ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(audio_file)
            
            # ë°œìŒ ì²´í¬ ë²„íŠ¼
            if st.button("MIC", key="mic_button_" + str(i)):
                if st.session_state.current_word:
                    spoken_text = speech_to_text()
                    if spoken_text:
                        similarity = calculate_similarity(st.session_state.current_word, spoken_text)
                        st.session_state.total_attempts += 1
                        
                        if similarity > 0.8:
                            st.success(f"ì •í™•í•©ë‹ˆë‹¤! (ìœ ì‚¬ë„: {similarity:.2%})")
                            st.session_state.score += 1
                            st.balloons()  # ì„±ê³µì‹œ í’ì„  íš¨ê³¼ ì¶”ê°€
                        else:
                            st.error(f"ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”. ì¸ì‹ëœ ë‹¨ì–´: {spoken_text} (ìœ ì‚¬ë„: {similarity:.2%})")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        st.write(f"ë‹¹ì‹ ì´ ë§í•œ ë‹¨ì–´: {spoken_text}")
                        st.write(f"ëª©í‘œ ë‹¨ì–´: {st.session_state.current_word}")
                else:
                    st.warning("ë¨¼ì € 'ìƒˆ ë‹¨ì–´ ë°›ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
            st.write("")  


    # ë„ì›€ë§
    with st.expander("ì‚¬ìš© ë°©ë²•"):
        st.write("""
        1. ìƒë‹¨ì—ì„œ ìºë¦­í„°(Boy/Girl)ë¥¼ ì„ íƒí•˜ì„¸ìš”.
        2. 'ìƒˆ ë‹¨ì–´ ë°›ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        3. ë‹¨ì–´ì˜ ë°œìŒì„ ë“¤ì–´ë³´ë ¤ë©´ ì¬ìƒ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
        4. 'ë°œìŒ ì²´í¬í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë‹¨ì–´ë¥¼ ë§í•´ë³´ì„¸ìš”.
        5. ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ì ìˆ˜ë¥¼ ë†’ì—¬ë³´ì„¸ìš”!
        """)

if __name__ == "__main__":
    main()
