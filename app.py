import streamlit as st
import random
from gtts import gTTS
import os
import tempfile
import speech_recognition as sr
import logging
import time
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import queue
import threading
import av
import numpy as np
import pydub
import io

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="English Pronunciation Practice", layout="centered")

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    .main { padding: 2rem; }
    .word-display {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        padding: 2rem;
        margin: 1rem 0;
        background-color: #f0f2f6;
        border-radius: 10px;
    }
    .status-area {
        margin: 1rem 0;
        padding: 1rem;
        border-radius: 5px;
    }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'words' not in st.session_state:
    st.session_state.words = [
        'apple', 'banana', 'chocolate', 'diamond', 'elephant',
        'flower', 'guitar', 'hamburger', 'island', 'jungle',
        'kitchen', 'lemon', 'monkey', 'notebook', 'orange'
    ]

if 'current_word' not in st.session_state:
    st.session_state.current_word = random.choice(st.session_state.words)

if 'transcript' not in st.session_state:
    st.session_state.transcript = ""

if 'audio_buffer' not in st.session_state:
    st.session_state.audio_buffer = []

# ìŒì„± ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
class AudioProcessor:
    def __init__(self):
        self.audio_buffer = []
        self.recording = False
        self.audio_queue = queue.Queue()

    def process_audio(self, frame):
        if self.recording:
            sound = frame.to_ndarray()
            self.audio_buffer.extend(sound.flatten().tolist())

    def start_recording(self):
        self.recording = True
        self.audio_buffer = []

    def stop_recording(self):
        self.recording = False
        return np.array(self.audio_buffer, dtype=np.int16)

# TTS í•¨ìˆ˜
@st.cache_data
def get_tts_audio(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    try:
        tts = gTTS(text=text, lang='en')
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
            tts.save(fp.name)
            return fp.name
    except Exception as e:
        logger.error(f"TTS error: {str(e)}")
        return None

# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def process_audio_data(audio_data, sample_rate=16000):
    """ìŒì„± ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    try:
        # WAV íŒŒì¼ë¡œ ë³€í™˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_wav:
            # WAV íŒŒì¼ ìƒì„±
            with wave.open(temp_wav.name, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(sample_rate)
                wf.writeframes(audio_data.tobytes())

            # ìŒì„± ì¸ì‹
            recognizer = sr.Recognizer()
            with sr.AudioFile(temp_wav.name) as source:
                audio = recognizer.record(source)
                text = recognizer.recognize_google(audio, language='en-US')
                return text.lower()
    except Exception as e:
        logger.error(f"Error processing audio: {str(e)}")
        return None
    finally:
        if os.path.exists(temp_wav.name):
            os.unlink(temp_wav.name)

# ë©”ì¸ ì•± UI
st.title("English Pronunciation Practice")
st.markdown("---")

# í˜„ì¬ ë‹¨ì–´ í‘œì‹œ
st.markdown(f'<div class="word-display">{st.session_state.current_word}</div>', unsafe_allow_html=True)

# ë°œìŒ ë“£ê¸° ë²„íŠ¼
if st.button("ğŸ”Š Listen to Pronunciation"):
    audio_file = get_tts_audio(st.session_state.current_word)
    if audio_file:
        st.audio(audio_file)
        os.unlink(audio_file)
    else:
        st.error("Could not generate pronunciation audio. Please try again.")

# ìƒˆë¡œìš´ ë‹¨ì–´ ì„ íƒ
if st.button("ğŸ”„ New Word"):
    st.session_state.current_word = random.choice(st.session_state.words)
    st.session_state.transcript = ""
    st.experimental_rerun()

# ë…¹ìŒ ì„¹ì…˜
st.markdown("### Record your pronunciation")
st.markdown("Click 'START' to begin recording and 'STOP' when finished.")

audio_processor = AudioProcessor()

def video_frame_callback(frame):
    """ë¹„ë””ì˜¤ í”„ë ˆì„ ì½œë°± (ì˜¤ë””ì˜¤ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ë¹ˆ í”„ë ˆì„ ë°˜í™˜)"""
    return frame

def audio_frame_callback(frame):
    """ì˜¤ë””ì˜¤ í”„ë ˆì„ ì½œë°±"""
    audio_processor.process_audio(frame)
    return frame

# WebRTC ìŠ¤íŠ¸ë¦¬ë¨¸ ì„¤ì •
ctx = webrtc_streamer(
    key="speech-to-text",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    video_receiver_size=0,
    rtc_configuration={
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    },
    video_frame_callback=video_frame_callback,
    audio_frame_callback=audio_frame_callback,
    media_stream_constraints={
        "video": False,
        "audio": True,
    },
)

# ë…¹ìŒ ì œì–´
if ctx.state.playing:
    if st.button("Start Recording"):
        audio_processor.start_recording()
        st.session_state.recording = True
        st.info("Recording... Speak now!")

    if st.button("Stop Recording"):
        if hasattr(st.session_state, 'recording') and st.session_state.recording:
            audio_data = audio_processor.stop_recording()
            st.session_state.recording = False
            
            if len(audio_data) > 0:
                # ìŒì„± ì²˜ë¦¬
                transcript = process_audio_data(audio_data)
                
                if transcript:
                    st.session_state.transcript = transcript
                    st.markdown("### Your pronunciation:")
                    st.write(st.session_state.transcript)
                    
                    if st.session_state.transcript.strip() == st.session_state.current_word:
                        st.success("âœ¨ Correct! Well done!")
                        st.balloons()
                    else:
                        st.error(f"Not quite right. Try again! You said: '{st.session_state.transcript}'")
                else:
                    st.warning("Could not recognize speech. Please try again.")
            else:
                st.warning("No audio recorded. Please try again.")

# ë„ì›€ë§
with st.expander("â„¹ï¸ Tips for better recognition"):
    st.markdown("""
    1. **Speak clearly**: Pronounce each word distinctly
    2. **Proper distance**: Keep your microphone about 6-12 inches from your mouth
    3. **Quiet environment**: Minimize background noise
    4. **Check volume**: Make sure your microphone volume is at an appropriate level
    5. **Browser settings**: 
       - Allow microphone access when prompted
       - Use a modern browser (Chrome recommended)
       - Ensure stable internet connection
    
    If you're having problems:
    - Refresh the page
    - Check microphone permissions
    - Try using a different microphone
    - Clear browser cache
    """)